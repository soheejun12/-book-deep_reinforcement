{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter3 Deep learning with PyTorch \n",
    "#### 이번장에서는 \n",
    "- PyTorch 라이브러리 구체화 및 구현 세부사항에 익숙해지는 것 \n",
    "- tensor\n",
    "\n",
    "\n",
    "## Tensor\n",
    "#### :  다차원 배열 \n",
    "#### : numpy에서 배열은 실제로는 tensor \n",
    "\n",
    "<img src=\"./image/tensor.png\" width=500>\n",
    "\n",
    "\n",
    "#### - 차원 \n",
    "- 0차원(점) : 하나의 단일 숫자 \n",
    "- 1차원(선분) : 벡터\n",
    "- 2차원 : 행렬\n",
    "- 3차원 이상 : 다차원 행렬(텐서)\n",
    "\n",
    "\n",
    "#### - type \n",
    "- pytorch에서는 8개의 type 지원 \n",
    "    - float형 3 개 : 16 비트, 32 비트 및 64 비트\n",
    "    - integer형 5개 : 부호있는 8 비트, 부호없는 8 비트, 16 비트, 32 비트, 64 비트\n",
    "    \n",
    "    \n",
    "- 자주 사용되는 종류 \n",
    "    - torch.FloatTensor (32비트 float)\n",
    "    - torch.ByteTensor (8비트의 부호없는 integer)\n",
    "    - torch.LongTensor (64비트 부호있는 integer)\n",
    "\n",
    "###  tensor 생성 방법 \n",
    "- 1. 필요한 형식의 생성자 호출하기 \n",
    "- 2. numpy배열 또는 파이썬 list를 텐서로 변환하기 \n",
    "- 3. pytorch에게 특정 데이터가 있는 텐서를 생성하도록 요청하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 필요한 형식의 생성자 호출하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [1.2771e-40, 9.0079e+15],\n",
       "        [1.6751e-37, 2.9775e-41]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(3, 2) #(행, 열)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초기화되지 않은 텐서 \n",
    "- 기본적으로 pytorch는 텐서용 메모리를 할당하지만 초기화는 하지 않음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#텐서 초기화 \n",
    "a.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. numpy배열 또는 파이썬 list를 텐서로 변환하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list\n",
    "torch.FloatTensor([[1, 2, 3], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array \n",
    "n = np.zeros(shape=(3, 2)) #기본적으로 double(float64)\n",
    "torch.tensor(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. pytorch에게 특정 데이터가 있는 텐서를 생성하도록 요청하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * tensor 연산 \n",
    "#### - inplace \n",
    "- 함수 이름 뒤에 밑줄(_) 추가 \n",
    "- 텐서의 내용에 직접 작용\n",
    "- 연산 후 객체 반환 \n",
    "- 성능 및 메모리면에서 효율적\n",
    "\n",
    "#### - functional equivalent\n",
    "- 복사본을 만들어 함수 작용 \n",
    "\n",
    "#### - 예)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, 2)\n",
    "y = torch.zeros(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(2 * x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y #객체에 직접 작용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- functional equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, 2)\n",
    "y = torch.zeros(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add(2 * x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y #복사본 생성 #원본 객체에는 영향 없음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * tensor type 명시적 지정\n",
    "- 일반적으로 딥러닝에서는 32, 16비트의 float형을 사용하는 것이 바람직 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3, 2), dtype=np.float32) ##\n",
    "torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3, 2))\n",
    "torch.tensor(n, dtype=torch.float32) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar Tensors\n",
    "- pytorch 0.4.0 버전부터 0차원 텐서(스칼라) 지원\n",
    "\n",
    "### 생성 및 접근 \n",
    "- torch.tensor()\n",
    "- item()\n",
    "    - 실제 파이썬 값에 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = a.sum()\n",
    "s #scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.item() #파이썬 값에 접근 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensor operations \n",
    "http://pytorch.org/docs/ \n",
    "#### - inplace\n",
    "- 객체에 직접 작용\n",
    "\n",
    "\n",
    "#### - functional equivalent \n",
    "- 객체를 복사해서 작용 \n",
    "\n",
    "\n",
    "#### - torch package \n",
    "- 함수의 인자는 일반적으로 텐서 \n",
    "\n",
    "\n",
    "#### - tensor class\n",
    "- 호출된 텐서에서 작동 \n",
    "\n",
    "\n",
    "\n",
    "** numpy에 별로 특화되지 않은 함수는 pytorch에서도 사용 가능 \n",
    "    - torch.stack()\n",
    "    - torch.transpose()\n",
    "    - torch.cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Tensors \n",
    "- pytoch는 CUDA GPU 지원 \n",
    "- 조작되고있는 텐서의 type에 따라 작업에서 CPU, GPU 자동 선택됨 \n",
    "- 앞에서 언급한 텐서들은 CPU용 \n",
    "- GPU용 텐서는 torch.cuda 패키지에 존재 \n",
    "\n",
    "### tensor를 CPU에서 GPU로 변환하기 \n",
    "#### - 텐서의 복사본을 지정된 device(CPU/GPU)에 생성 \n",
    "- 텐서가 device에 이미 존재하면 기존 텐서 반환\n",
    "\n",
    "#### 1. device의 문자열 전달 \n",
    "- CPU : \"cpu\"\n",
    "- GPU : \"cuda\"\n",
    "    - 1번째 GPU 카드: \"cuda: 0\"\n",
    "    - 2번째 GPU 카드: \"cuda: 1\" \n",
    "    \n",
    "#### 2. torch.device.class 사용 \n",
    "- device이름과 선택적 인덱스 허용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([2, 3]) #cpu에 생성 \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-37f7464e6dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#gpu에 복사\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openai/env/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         raise RuntimeError(\n\u001b[1;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openai/env/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "ca = a.cuda() #gpu에 복사 \n",
    "ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a50fcd5a8e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mca\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ca' is not defined"
     ]
    }
   ],
   "source": [
    "ca + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-512f3cc115d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ca' is not defined"
     ]
    }
   ],
   "source": [
    "ca.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "### 그래디언트 계산 방법 \n",
    "#### 1. 정적그래프 \n",
    "- tensorflow, theano 등에서 사용하는 방법 \n",
    "- 미리 그래프(계산)를 정의 (이 후 변경 불가능)\n",
    "- 그래프는 계산이 진행되기 전에 딥러닝 라이브러리에 의해 처리되고 최적화됨 \n",
    "\n",
    "#### 2. 동적그래프 \n",
    "- pytoch, chainer 등에서 사용하는 방법 \n",
    "- 그래프를 미리 정의하지 않음 \n",
    "- 실제 데이터에서 데이터 변환에 사용하려는 작업만 실행하면 됨 \n",
    "    - 이 때, 라이브러리는 수행된 작업 순서를 기록,\n",
    "    - 그래디언트를 계산하도록 요청하면,\n",
    "        - 작업 기록을 unroll \n",
    "        - 네트워크 파라미터의 그래디언트를 축적(accmulate)\n",
    "        - notebook gradient 방법이라고도 불림 \n",
    "        \n",
    "        \n",
    "- 계산 오버헤드는 높지만 개발자가 더 자유로워짐 \n",
    "    - 그래디언트에 대한 자유로운 조작 가능 \n",
    "    \n",
    "    \n",
    "- 계산과 메모리 측면에서의 효율성이 높음 \n",
    "    \n",
    "## Tensors and gradients\n",
    "- pytorch 텐서에는 그래디언트  계산 및 추적 기능이 내장되어있음 \n",
    "\n",
    "\n",
    "<img src=\"./image/gradients.png\" width=400>\n",
    "\n",
    "### 그래디언트와 관련된 tensor의 속성 \n",
    "#### - grad\n",
    "- 계산된 그래디언트를 포함하는 동일한 형태의 텐서를 보유하는 속성 \n",
    "\n",
    "\n",
    "#### - is_leaf\n",
    "- True: 텐서가 사용자에의해 생성 \n",
    "- False: 객체가 함수변환의 결과 \n",
    "\n",
    "\n",
    "#### - requires_grad \n",
    "- leaf 텐서에서 상속된 속성 \n",
    "- True: 그래디언트가 계산되는 텐서 \n",
    "- False: (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1.0, 1.0], requires_grad=True) #calculates gradient \n",
    "v2 = torch.tensor([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 그래프 생성 예제\n",
    "<img src=\"./image/graph.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum = v1 + v2 \n",
    "\n",
    "v_res = (v_sum * 2).sum()\n",
    "\n",
    "v_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- leaf node(사용자가 생성): v1, v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래디언트를 계산하는지: v1, v_sum, v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad, v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad, v_res.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프의 그래디언트 계산 \n",
    "    - backward(): 그래프에 있는 다른 변수들에 대하여 해당 변수의 미분을 계산\n",
    "        - 그래프 내의 다른 변수들의 변화가 해당 변수에 어떤 영향을 끼치는지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v1의 각 값이 1 증가하면 v_res의 값은 2 증가한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2.grad #requires_grad=Fasle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_res.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_sum.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN building blocks \n",
    "### torch.nn 패키지 \n",
    "#### - 패키지 내의 모든 클래스는  nn.Module 기본클래스에서 상속받음 \n",
    "\n",
    " http://pytorch.org/docs의\n",
    " \n",
    "#### - 간단한 예제 (LInear model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6548, -0.7220,  1.7513, -1.6557, -0.0152], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Linear(2, 5) #nn.Linear(n_inputs, n_outputs)\n",
    "\n",
    "v = torch.FloatTensor([1, 2])\n",
    "\n",
    "l(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 무작위로 초기화된 feed-forward 레이어 생성 \n",
    "- 두개의 입력, 5개의 출력 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sequential \n",
    "- 다른 레이어를 파이프에 결합할 수 있게 해주는 클래스 \n",
    "- 예)\n",
    "- fc-relu-fc-relu-dropout-softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Sequential(nn.Linear(2, 5), #(n_inputs, n_outputs)\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(5, 20), \n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(20, 10), \n",
    "                  nn.Dropout(p=0.3), \n",
    "                  nn.Softmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): Dropout(p=0.3)\n",
       "  (6): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1433, 0.0995, 0.1524, 0.0798, 0.0721, 0.0844, 0.0914, 0.0995, 0.0783,\n",
       "         0.0995]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(torch.FloatTensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers\n",
    "### nn.Module이 자식에게 제공하는 기능 \n",
    "#### - 현재 모듈에 포함된 모든 서브모듈 추적 \n",
    "- 하나의 모듈에는 여러개의 모듈 존재 가능 \n",
    "\n",
    "\n",
    "#### - 등록된 서브 모듈의 모든 매개변수 처리 \n",
    "#### - nn.Module 자식이 제공하는 메소드 \n",
    "- parameters(): 그래디언트 계산이 필요한 모든 변수의 iterator(모듈 가중치) 반환\n",
    "- zero_grad(): 모든 파라미터의 모든 그래디언트 0으로 초기화 \n",
    "- to (device): 모든 모듈 매개변수를 지정된 장치(CPU, GPU)로 이동 \n",
    "- state_dict(): 모든 모듈 파라미터가 있는 사전을 반환 (모델 직렬화에 유용)\n",
    "- load_state_dict(): 상태 사전으로 모듈 초기화 \n",
    "- apply(): 일반 변화 수행 \n",
    "\n",
    "#### - 데이터에 모듈 어플리케이션 규칙 설정 가능 \n",
    "- 모든 모듈은 오버라이팅하여 forward() 메소드에서 데이터변환을 수행해야함 \n",
    "\n",
    "#### - 코드 단순성과 재사용에 매우 편리 \n",
    "- nn.Module 규칙에 따르면 one-layer Linear 변환이나 1001 layer의 ResNet을 같은 방식으로 처리 가능 \n",
    "\n",
    "\n",
    "### 모듈 생성 간소화 방법 \n",
    "#### 1. 하위모듈 등록 \n",
    "#### 2. forward()  메소드 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
    "        super(OurModule, self).__init__() #부모생성자 호출을 통해 초기화 \n",
    "        \n",
    "        #모듈을 필드에 할당 \n",
    "        self.pipe = nn.Sequential(nn.Linear(num_inputs, 5), \n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Linear(5, 20), \n",
    "                                  nn.ReLU(), \n",
    "                                  nn.Linear(20, num_classes), \n",
    "                                  nn.Dropout(p=dropout_prob), \n",
    "                                  nn.Softmax(dim=1))\n",
    "        \n",
    "    \n",
    "    #forward() Overriding \n",
    "    #데이터변환 구현 \n",
    "    #이 모듈은 다른 레이어를 둘러싼 매우 단순한 wrapper이므로 데이터 변환을 요청하기만 하면 됨 \n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 데이터에 모듈을 적용하기\n",
    "- 1. 모듈 인스턴스를 함수처럼 인자를 넘겨서 사용해야함 \n",
    "\n",
    "- 2. nn.Module (부모) 클래스의 forward() 함수를 사용하지 않아야 함\n",
    "    - nn.Module이 __call__()메소드를 오버라이딩함 \n",
    "    - forward()를 직접 호출하면 부모의 개입 발생 가능 \n",
    "    \n",
    "    \n",
    "- **이를 통해 부모의 magic stuff, 내가 overriding한 forward() 사용 가능**\n",
    "    \n",
    "### 모듈 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    net = OurModule(num_inputs=2, num_classes=3) #원하는 크기의 모듈 생성 \n",
    "    \n",
    "    v = torch.FloatTensor([[2, 3]])\n",
    "    \n",
    "    out = net(v) #함수처럼 사용 (데이터를 인자로 넘겨줌)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurModule(\n",
       "  (pipe): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
       "    (5): Dropout(p=0.3)\n",
       "    (6): Softmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3153, 0.3693, 0.3153]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **forward( )** \n",
    "    - 모든 데이터 배치에 대한 제어권을 얻음\n",
    "    - 더 복잡한 연산 수행 가능 \n",
    "    \n",
    "- 모듈에 대한 인수(argument)의 개수는 하나의 파라미터로 제한되지 않음 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "- loss function: 네트워크의 예측이 원하는 결과와 얼마나 가까운지 \n",
    "- loss value: loss function의 출력값 \n",
    "\n",
    "#### - nn 패키지에 존재 \n",
    "- nn.Module의 하위클래스로 구현됨 \n",
    "- 일반적으로 네트워크의 출력과 원하는 출력을 인수로 받음 \n",
    "\n",
    "#### - 가장 일반적으로 사용되는 손실함수 \n",
    "- **nn.MSELoss**\n",
    "- **nn.BCELoss**, **nn.BCEWithLogits**\n",
    "    - Binary교차 엔트로피 손실 (이진 분류에서 자주 사용)\n",
    "    \n",
    "  \n",
    "- **nn.CrossEntropyLoss**, **nn.NLLLoss**\n",
    "    - maximum likelihood 기준으로, 다중클래스 분류문제게 사용 \n",
    " \n",
    "## Optimizers\n",
    "#### - 역할\n",
    "- 손실값을 줄이기위해 모델 파라미터의 그래디언트를 취해 파라미터를 변경하는 것 \n",
    "\n",
    "#### - torch.optim 패키지에 구현 \n",
    "#### - 널리 사용되는 optimizer\n",
    "- **SGD**\n",
    "- **RMSProp**\n",
    "- **Adagrad**\n",
    "\n",
    "\n",
    "### 최적화 수행 알고리즘 (7단계)\n",
    "#### 1. 데이터를 배치로 분할 \n",
    "#### 2. 모든 배치에는 데이터 샘플과 대상 레이블 포함 \n",
    "- 두 데이터 모두 텐서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_samples, batch_labels in iterate_batches(data, batch_size=32): \n",
    "    batch_samples_t = torch.tensor(batch_samples)\n",
    "    batch_labels_t = torch.tensor(batch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터 샘플을 네트워크로 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_t = net(batch_sampels_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 네트워크 출력 및 대상 레이블을 손실함수에 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_t = loss_function(out_t, batch_labels_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 네트워크 전체에 대한 그래디언트 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_t.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 최적화 작업 수행 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 매개변수의 그래디언트를 0으로 만들기 \n",
    "- 네트워크에서 zero_grad() 호출 \n",
    "- optimizer가 zero_grad() 호출 (#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring with TensorBoard \n",
    "#### - 학습 과정을 확인하고 그 역학을 관찰하기위해 사용 \n",
    "\n",
    "#### -  tensorboard-pytorch 사용 \n",
    "- https://github.com/lanpa/tensorboard-pytorch\n",
    "- pip install tensorboard-pytorch \n",
    "\n",
    "#### - 예제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    writer = SummaryWriter() #데이터 작성자 생성 \n",
    "    \n",
    "    funcs = {\"sin\": math.sin, \n",
    "             \"cos\": math.cos, \n",
    "             \"tan\": math.tan}\n",
    "    \n",
    "    for angle in range(-360, 360):\n",
    "        angle_rad = angle * math.pi/180 #라디안 \n",
    "        \n",
    "        for name, fun in funcs.items():\n",
    "            val = fun(angle_rad)\n",
    "        \n",
    "            writer.add_scalar(name, val, angle) #작성자에 전달 \n",
    "            \n",
    "    writer.close() #작성자 종료 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/tensorboard_example.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Gan on Atari images \n",
    "#### : GAN(Generative Adversarial Networks)를 통해 다양한 atari 게임 스크린샷 생성 \n",
    "- GAN: 두개의 네트워크(생성자, 판별자)가 서로 경쟁하며 학습 \n",
    "    - 생성자: 판별자가 실제 데이터와 구별하기 어려운 가짜 데이터 생성하려 시도  \n",
    "    - 판별자: 실제 데이터와 가짜 데이터를 구별하려시도\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**atari-gan.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wrapper 클래스 정의 \n",
    "    - 배열의 입력을 처리 \n",
    "    - 정해진 크리고 이미지 resize\n",
    "    - 첫번째 place로 컬러 채널 축을 이동 \n",
    "        - pytorch의 convolution 레이어는 (channel, height, width)\n",
    "        \n",
    "        \n",
    "- Discriminator (판별자) 클래스\n",
    "    - 스케일링된 컬러 이미지 입력\n",
    "    - 5개의 convolution layer \n",
    "    - sigmoid 출력 \n",
    "    \n",
    " \n",
    "- Generator (생성자) 클래스\n",
    "    - 가짜 이미지 생성 \n",
    "    - 5개의 convolution layer \n",
    "    - tanh 출력 \n",
    "    \n",
    "    \n",
    "- iterate_batches()  함수 \n",
    "    - 배치 생성 \n",
    "    - 각 환경에 대해 랜덤 액션을 수행한 결과(관찰) \n",
    "    \n",
    "    \n",
    "- main\n",
    "    - 환경 생성 \n",
    "    - 네트워크 생성 (판별자, 생성자)\n",
    "    - 손실 정의 \n",
    "    - 라벨 정의 \n",
    "    - 판별자, 생성자 학습 \n",
    "    - 생성된 가짜 이미지, 실제 이미지 저장\n",
    "    - 각 네트워크 손실 저장\n",
    "    \n",
    "    \n",
    "#### - 주요함수 \n",
    "- nn.Conv2d(in_channels=입력크기, out_channels=출력크기, kernel_size, stride, padding)\n",
    "\n",
    "- nn.ConvTransposed2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "    - deconvolution \n",
    "    \n",
    "- nn.ReLU()\n",
    "- nn. BatchNorm2d\n",
    "    - 4차원 입력에대해 batch normalization수행 \n",
    "    \n",
    "\n",
    "- view(shape)\n",
    "    - reshape tensor \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/server-11100.png\">\n",
    "<img src=\"./image/server-84000.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://m.blog.naver.com/PostView.nhn?blogId=fastcampus&logNo=221029365132&proxyReferer=https%3A%2F%2Fwww.google.com%2F\n",
    "\n",
    "https://tensorflow.blog/2017/02/28/pytorch-vs-tensorflow/\n",
    "\n",
    "https://dev-strender.github.io/articles/2018-02/comparison-of-deep-learning-tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
